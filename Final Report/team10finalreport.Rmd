---
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \headheight 35pt
- \fancyhead[LE,LO]{Abowath, Blakely, \\ Garrison, Loui, Peir \\}
- \fancyhead[CO,CE]{\textbf{\Large Forecasting Bikesharing Usage \\ Team 10 - Final Report} \\ https://github.gatech.edu/MGT-6203-Fall-2023-Canvas/Team-10}
- \fancyhead[RE,RO]{MGT 6203 \\ Fall 2023 \\}
- \fancyfoot[RE,RO]{\small \thepage}
- \fancyfoot[CE,CO]{}
- \headsep 1.5em
output: pdf_document
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
require(gridExtra)
library(kableExtra)
library(broom)
library(forecast)
library(data.table)
library(lightgbm)
set.seed(123)

final_df <- read_csv('../Data/final_df.csv') |>
  mutate(
    season = factor(season),
    day_of_week = factor(day_of_week)
  ) |>
  select(-...1, -mnth_date)
levels(final_df$season) <- c('winter', 'spring', 'summer', 'fall')
levels(final_df$day_of_week) <- c('Sun', 'Mon', 'Tue', 'Wed', 'Thur', 'Fri', 'Sat')
```

# Forecasting Bikesharing Usage for DC's Capital Bikshare System

# Table of Contents

* Introduction
* Overview of Project
* Overview of Data
* Overview of Modeling
* Conclusion
* Literature Review Summary
* Works Cited

# Introduction

Bike sharing systems are an increasingly popular solution in major urban areas to increase the usage of bicycles as a mode of transport. Bike usage improves the lives of users by providing exercise, but also helps non-users since more trips taken by bike leads to a reduction in the number of cars on the road and $CO_2$ emissions. We studied usage data from Washington DC's Capital Bikeshare from 2011 to 2017 and corresponding weather data. 

The purpose of this analysis is to determine variables/factors that help estimate bike usage and develop a model that forecasts the usage based on weather, day of week, and season.

# Overview of Project

The idea of the project was to use different modeling techniques to determine if we could forecast the bike usage. If we are able to model and forecast bikeshare usage, then it would allow Capital Bikeshare (or any agency/company running a bikesharing program) to plan for the best times to increase their fleet as well as expanding the available stations that are offered. A station is a location where the bikes are stored and can be rented.

Some of the questions were: 

* Can we use the data to forecast when our usage is lower to potentially remove some bikes from service for maintenance? 
* When should we start increasing our fleet to best meet demand? 
* Do weather or seasons have an impact on usage? 

We made an initial hypothesis that we would see a higher usage during the summer, and when the weather was nice (moderate temperature, no precipitation, low windspeed). Initial exploratory data analysis (EDA) indicated that these hypotheses appeared true. Usage tends to be highest in spring and summer, and usage generally increases as temperature increases, and decreases as precipitation and windspeed increase. However, in addition to pronounced seasonality, we identified that there was a trend towards increased usage of the system over time. The question then became, can we model this through a time series model? Also, could we see what features were key factors in determining bike usage. Which factors overall appear to have the greatest impact?


# Overview of Data

## Initial Data Set:

We started by just looking at two years of Capital Bikeshare usage from this dataset: [https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset)

The dataset contains 2011 and 2012 historical usage data from Washington DCâ€™s public Capital Bikeshare program. This is one of the first large scale 
bikeshare programs in the nation. Usage data is broken out by day and by hour. Additional data included a variety of information on weather, season, and whether a day was a holiday.

## Data Cleaning Process

The dataset had required minimal cleaning. We had to convert several variables into factor variables (`season`, `holiday`, `weekday`, `workingday`, `weather`). Additionally we noted that the key for our dataset mislabeled the season variable, which was trivial to correct. Fortunately, there was no missing data.

### Additional Scraping, Cleaning

Initial exploratory data analysis (EDA) indicated we did not have sufficient data to fit any models more complex than linear regression. We found that we could download additional Capital Bikeshare usage data. Because Capital Bikeshare's usage data did not include weather data, we decided to also scrape weather data. 

We used python scripts located in the `Other Resources` directory to do this. 

Specifically, we ran `get_bikeshare_data.py` to get bikeshare data from Capital Bikeshare's website directly, then we ran `join_data.py` (which imports from `noaa.py`) to join the data with weather data from the NOAA API. All these code files can be found in our `Other Resources` directory.

Upon scraping the additional data, we combined this with our initial data set to create a new dataset that spanned from 2011 to 2017. We also added a few new feature variables such as `season`, which was missing from the new scraped dataset.

Instead of forecasting on a daily basis, we created a second dataset that reflected weekly usage. To create the weekly data set, we calculated the mean of usage across each week that would be used for time series models. This weekly dataset will help smooth over any outliers, but they wouldn't be removed. It allowed for a cleaner, more presentable dataset. It makes sense to use a weekly dataset, since you don't want your employees to have to constantly change bike quantities on a daily basis, but at least a weekly timeframe.

Therefore, we had one dataset that we performed EDA and performed linear regression and LightGBM on. All time series models were run against the weekly dataset.

#### The Weather data included:

* `TMAX`: high temperature (in tenths of degree Celsius), 
* `PRCP`: precipitation (tenths of mm), and 
* `AWND`: average daily wind speed (km/h). 

The final merged dataset used for analysis is `final_df.csv` located in the `Data` folder.

### Sources for additional datasets:

* Capital Bikeshare usage data from 01-01-2013 through 12-31-2017, from
Capital Bikeshare (https://ride.capitalbikeshare.com/system-data)
* Weather data for DC for the same time period, from NOAA (https://www.ncdc.noaa.gov/cdo-web/webservices/v2)

## Exploratory Data Analysis

We can see that fortunately, Bikeshare usage per day is not heavily skewed, but aligns more towards to a normal distribution.

```{r hist_plots, echo=F, out.width="60%", fig.align="center", message=FALSE}
usage_hist <- final_df %>% 
  ggplot() +
  geom_histogram(mapping = aes(cnt), fill = 'red', alpha = 0.5) +
    labs(
    x = "Bike Usage per Day",
    y = "Density",
    title = "Bikeshare Usage Per Day"
  )

temp_hist <- final_df %>% 
  ggplot() +
  geom_histogram(mapping = aes(TMAX), fill = 'red', alpha = 0.5) +
  labs(
    x = "Daily High Temperature",
    y = "Density",
    title = "Temperature Distribution",
    subtitle = "Tenths of Degree Celsius"
  )

prec_hist <- final_df %>% 
  ggplot() +
  geom_histogram(mapping = aes(PRCP), fill = 'red', alpha = 0.5, bins = 100) +
  labs(
    x = "Precipitation in mm",
    y = "Density",
    title = "Precipitation Distribution"
  )

windspeed_hist <- final_df %>%
  ggplot() +
  geom_histogram(mapping = aes(AWND), fill = 'red', alpha = 0.5, bins = 100) +
  labs(
    x = "Wind Speed in km/h",
    y = "Density",
    title = "Wind Speed Distribution"
  )

grid.arrange(usage_hist, temp_hist, prec_hist, windspeed_hist, ncol=2)
```

We can see that the temperature distribution has a leftward skew. This makes intuitive since because there would be fewer cold days.

We can also see that wind speed and precipitation exhibit rightward skew, which makes sense:

* Most days have no precipitation
* Most days have moderate wind speed, while a few have very high wind speed

The data depicts that there is a "steady" state for each of the distributions that the data is trying to form around. We expect that in general we would have warmer days with less rain and low wind speeds. 

```{r weekday_usage, echo=F, out.width="60%", fig.align="center"}
final_df %>% 
  ggplot(mapping = aes(day_of_week, cnt, color = season)) +
  geom_boxplot() +
  labs(
    x = "Weekday",
    y = "Total Bike Usage",
    title = "Total Bike Usage",
    subtitle = "Given Weekday and Season"
  )
```

We can see in the above chart the effect of season on the bike share usage. Usage is lowest in the winter, highest in the summer, with spring and fall in between. For the most part, the usage per weekday seems to be consistent with minor fluctuation (correlating seasons). Fortunately, there is not a huge amount of variation in usage between weekdays and weekends.

```{r weekday_usage2, echo=F, out.width="60%", fig.align="center"}
final_df %>% 
  ggplot(mapping = aes(dteday, cnt, color = season)) +
  geom_point() +
  labs(
    x = "Date",
    y = "Total Bike Usage",
    title = "Total Bike Usage",
    subtitle = "Total Bike Usage Across All Times in Combined Dataset"
  ) +
  coord_fixed(ratio = 0.08)
```

The most challenging aspect of our dataset is that usage was not static. It grew from 2011 through 2017, which shows an upward trend. While this was obviously good for Capital Bikeshare, it meant that models would need to take into account not just variation within a year but an upward trend.

```{r temp_usage, echo=F, out.width="60%", fig.align="center"}
temp_usage_plot <- final_df %>%
  ggplot(mapping = aes(TMAX, cnt, color = season)) +
  geom_point() +
  labs(
    x = "Max Temperature (Tenths of Degree Celsius)",
    y = "Total Bike Usage",
    title = "Total Bike Usage by Season relative to Temperature",
    subtitle = "Total Bike Usage vs. Temperature"
  ) #
  # coord_fixed(ratio = 0.008)
```

Consistent with our literature review, we see in the below image that as temperature increases usage tends to increase until around 30 degrees Celsius, after which usage tends to decrease.

```{r prcp_usage, echo=F, out.width="75%", fig.align="center"}
prcp_usage_plot <- final_df %>%
  ggplot(mapping = aes(PRCP, cnt, color = season)) +
  geom_point() +
  labs(
    x = "Precipitation (tenths of mm)",
    y = "Total Bike Usage",
    title = "Total Bike Usage by Season relative to Precipitation",
    subtitle = "Total Bike Usage vs. Precipitation",
  )
grid.arrange(temp_usage_plot, prcp_usage_plot, nrow = 2)
```

The relationship between precipitation and usage appears somewhat weaker than temperature. Still, the highest precipitation days tend not to have high usage, consistent with an overall negative effect of precipitation on usage. This is also somewhat hard to definitively define, unlike temperature, since rain isn't as consistent. You could almost see higher precipitation as an outlier in the data. 

```{r awnd_usage, echo=F, out.width="60%", fig.align="center"}
final_df %>%
  ggplot(mapping = aes(AWND, cnt, color = season)) +
  geom_point() +
  labs(
    x = "Average Daily Wind Speed (km/h)",
    y = "Total Bike Usage",
    title = "Total Bike Usage by Season relative to Wind Speed",
    subtitle = "Total Bike Usage vs. Windspeed"
  )
```
We can also see a slightly negative relationship between wind speed and usage.

A correlation matrix comparing our temperature, precipitation, wind speed and usage variables validates our graphical EDA:

* There is a positive correlation between temperature and count
* There are negative correlations between precipitation and count, as well as wind speed and count

```{r correlation_matrix, echo=F, out.width="75%", fig.align="center"}
final_df %>% 
  select(TMAX, PRCP, AWND, cnt) %>% 
  cor() |>
  kable()
```

We can also see the negative correlation of temperature with wind speed. Fortunately, precipitation has minimal correlation with temperature (-0.006) and relatively low correlation with wind speed (0.093). You would expect wind speed and precipitation to be somewhat correlated since there is often a breeze when it is raining.

## Key Predictors

The key predictors for time series will be time, which is made up of a trend and seasonality component.

We used LASSO to determine which predictors are key. LASSO is used for feature selection by reducing the estimated coefficient for a predictor. If a coefficient is zero, then that predictor may not have information about the response. After running this model, we see that `TMAX`, `PRCP`, `season.winter`, `season.spring`, `day_of_week.Sun`, `day_of_week.Mon`, `day_of_week.Wed` and `day_of_week.Sat` are not reduced to zero. Taking these predictors, we ran another linear regression model looking for which predictors were significant based on their `p-value`. 

Therefore, the key predictors that were used for classification models were `TMAX`, `PRCP`, `season.winter` and `day_of_week.Wed`.

# Overview of Modeling

For our modeling, we used the `final_df.csv` file in the `Data` directory, which is described in the accompanying readme on GitHub page. We also used an edited data set that converted the above dataset into weekly instead of daily for the time series models. We wanted to run models that were able to forecast usage in the future as well as evaluate the capability of classifying on a daily basis. We decided to use time series models to forecast usage in the future. We used different trees, gradient boosting and regression models to be able to classify the bike usage given some inputs.

## Model Types and Comparison

We ran multiple different models to try to best determine what fits the data best. Ideally since we are dealing with time series data, we are expecting that it will be the best at predicting. We decided to only showcase three of the models in this paper. The three are Linear Regression (with and without time series), ARIMA and LightGBM (gradient boosting). Other models were run and can be found in our `Code/Models` directory.

### Linear Regression

This is the very first model that we used as a base case. We also ran other basic linear regression models (LASSO, Ridge Regression, etc.) but they all seemed to perform similarly. The main problem was they were unable to fit the trend.

```{r linreg, echo=F, out.width="60%", fig.align="center", results='hide'}
model_df <- final_df |>
  select(-dteday)
fit <- lm(cnt ~ ., data = model_df)
summary(fit)
pred <- predict(fit, model_df)
naive.rmse <- sqrt(mean((pred - model_df$cnt)^2))
naive.rmse
# 2632.675

model_df |>
  ggplot(mapping = aes(x=final_df$dteday, y = cnt)) +
  geom_line(aes(color = 'Actual')) + 
  geom_line(mapping = aes(y = pred, color = 'Predicted'), alpha = 0.5) +
  labs(
    x = 'Time in Days',
    y = 'Bikeshare usage',
    title = "Linear Regression",
    subtitle = "Bikeshare usage on daily basis",
    color = 'Forecast',
    caption = paste("RMSE:", round(naive.rmse, 3))
  ) +
  scale_color_manual(values = c("Actual" = "black", "Predicted" = "red"))

```

A naive linear regression does not incorporate any time series factors such as trend. It has a poor RMSE (root mean square error), which can be seen in the caption above. We can see that the linear regression over-predicts usage in early years, and under-predicts usage in later years, due to lacking a trend/time series component. We can also see that on some days we predict that there will be almost a `-5000` bike usage, which is impossible. It is obvious that this does a poor job of predicting bike usage.

### Linear Regression with Time Series

Since we can see above that we are unable to predict without time series, we decided to create a model that attempts to predict with trend and seasonality.

```{r ts_dataframe, echo=F, results='hide', message=FALSE}
ts_df <- read_csv('../Data/final_df.csv') |>
  mutate(
    Date = dteday,
    season = factor(season),
    day_of_week = factor(day_of_week),
    Count = cnt
  ) |>
  mutate(week = as.Date(cut(Date, "week"))) |>
  group_by(week) |>
  summarize(count = mean(Count))

Y <- ts(ts_df$count, start = c(2010, 12), frequency = 52)
train_Y <- subset(Y, end = 314)
test_Y <- subset(Y, start = 315)
```

Therefore, for our next time series model, we used weekly average usage instead of daily actual usage. We implemented this change to get cleaner plots and reduced time in calculating some of the time series models. Due to the weekly using an mean of the week's bike share usage, this has a tendency to reduce outliers from affecting the trend by smoothing the data.

```{r linreg_ts, echo=F, out.width="60%", fig.align='center', results='hide', message=FALSE}
lm.fit <- tslm(train_Y ~ trend + season)
lm.fcst <- forecast(lm.fit, h = 52)
lm.rmse <- sqrt(mean((lm.fcst$mean - test_Y)^2))
# 1659.656

autoplot(train_Y) +
  autolayer(lm.fcst, series = 'Forecast', alpha=0.5) +
  autolayer(test_Y, series = 'Actual') +
  labs(
    title = "Time Series Linear Regression Model",
    subtitle = "Bikeshare usage on weekly basis",
    x = 'Time in Weeks',
    y = 'Average Weekly Bikeshare usage',
    caption = paste("RMSE:", round(lm.rmse, 3))
  ) +
  coord_fixed(ratio = 0.0003)
```

By changing the linear regression model to take in the trend and seasonality, we can see that we are doing fairly well at accurately forecasting the year of 2017. For this model using a test set, we have a RMSE of **1659.66**. The test set is the entire year of 2017. It was withheld from the training data.

### ARIMA

From EDA and the linear regression models, we know we need to be able to model the change over time or time series. One of the best models for dealing with Time Series is ARIMA and its derivatives. 

```{r arima, echo=F, out.width="60%", fig.align='center', results='hide', message=FALSE}
fit_arima <- arima(train_Y, order = c(3, 1, 1), seasonal = c(0, 1, 1))
arima.fcst <- forecast(fit_arima, h=52)
arima.rmse <- sqrt(mean((arima.fcst$mean - test_Y)^2))
# 1503.639

autoplot(train_Y) +
  autolayer(arima.fcst, series = 'Forecast', alpha = 0.5) +
  autolayer(test_Y, series = 'Actual') +
  labs(
    title = paste("Time Series ARIMA Model:", arima.fcst$method),
    subtitle = "Bikeshare usage on weekly basis",
    x = 'Time in Weeks',
    y = 'Average Bike usage',
    caption = paste("RMSE:", round(arima.rmse, 3))
  )
```

It was determined that the best ARIMA model for our data was `order = (3, 1, 1)` and `seasonal = (0, 1, 1)`. The model has an RMSE of **1503.639** for the test data. It was better able to forecast/predict the final year as compared to the time series linear regression model.

### LightGBM

We implemented a powerful and efficient gradient boosting framework to predict/forecast the usage for the later years. The Predicted year of 2017 is out of sample for training, and constitutes the test data set. Pre-2017, the predicted line describes the fitting on the training data set itself.

```{r Lightgbm, echo=F, out.width="75%", fig.align='center', results='hide', message=FALSE}

final_data <- read_csv('../Data/final_df.csv') |>
  select(
    Date = dteday,
    season = season, #factor(season),
    day_of_week = day_of_week,#factor(day_of_week),
    TMAX = TMAX,
    AWND = AWND,
    PRCP = PRCP,
    day = day,
    Count = cnt
  )
setDT(final_data)
final_data[,year := year(Date)]

final_data$season <- as.factor(final_data$season)
final_data$day <- as.factor(final_data$day)
final_data$TMAX <- as.numeric(final_data$TMAX)
final_data$PRCP <- as.numeric(final_data$PRCP)
final_data$AWND <- as.numeric(final_data$AWND)


train_data <- final_data[Date < '2017-01-01']
test_data  <- final_data[Date >= '2017-01-01']

suppressWarnings({
train_dataset <- lgb.Dataset(data = as.matrix(train_data[, -c("Count","Date")]),
                             label = train_data$Count,
                             categorical_feature = c("season", "day",
                                                     "day_of_week"
                             ))
})

suppressWarnings({
test_dataset <- lgb.Dataset(data = as.matrix(test_data[, -c("Count","Date")]),
                            label = test_data$Count,
                            categorical_feature = c("season", "day",
                                                    "day_of_week"
                            ))
})

# Specify LightGBM parameters
params <- list(objective = "regression",
               metric = "rmse",
               boosting_type = "gbdt")

# Train the LightGBM model
params$silent <- TRUE

# Train the LightGBM model for daily forecast
suppressWarnings({
  lgb_model <- lgb.train(params = params,
                         data = train_dataset,
                         nrounds = 100,
                         valids = list(test = test_dataset))
})
suppressWarnings({
lgb_pred <- predict(lgb_model, as.matrix(test_data[, -c("Count","Date")]))
})

lgb_rmse <- sqrt(mean((lgb_pred - test_data$Count)^2))

print(paste0("LightGBM RMSE Daily forecast:", lgb_rmse ))


df12 <- data.frame(
  Date = test_data$Date,
  Actual = test_data$Count,
  Predited = lgb_pred
)

suppressWarnings({
df12 = rbind(data.frame(
  Date = train_data$Date,
  Actual = train_data$Count,
  Predited = predict(lgb_model, as.matrix(train_data[, -c("Count","Date")]))
),
df12
)
})


# Plotting using ggplot2
day_wise <- ggplot(df12, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predited, color = "Predited")) +
  labs(
    title = "LightGBM Model by Day",
    subtitle = "Bikeshare usage Acutal vs Predicted",
    x = "Time in Days",
    y = "Average Bike Usage",
    caption = paste("RMSE:", round(lgb_rmse, 3))
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Predited" = "red")) +
  theme_minimal()

#---- Week wise ---#

final_data <- read_csv('../Data/final_df.csv') |>
  select(
    Date = dteday,
    season = season, #factor(season),
    day_of_week = day_of_week,#factor(day_of_week),
    TMAX = TMAX,
    AWND = AWND,
    PRCP = PRCP,
    day = day,
    Count = cnt
  )
setDT(final_data)
final_data[,year := year(Date)]

final_data <- final_data[,.(Date = min(Date), season = toString(unique(season)), TMAX = mean(TMAX), AWND = mean(AWND), PRCP = mean(PRCP), Count = mean(Count) ), 
           by = .(year(Date),mnth = month(Date),week(Date))]


final_data$season <- as.factor(final_data$season)
final_data$mnth <- as.factor(final_data$mnth)
final_data$TMAX <- as.numeric(final_data$TMAX)
final_data$PRCP <- as.numeric(final_data$PRCP)
final_data$AWND <- as.numeric(final_data$AWND)


train_data_week <- final_data[Date < '2017-01-01']
test_data_week  <- final_data[Date >= '2017-01-01']

suppressWarnings({
train_dataset_week <- lgb.Dataset(data = as.matrix(train_data_week[, -c("Count","Date")]),
                             label = train_data_week$Count,
                             categorical_feature = c("season", "mnth"
                             ))
})

suppressWarnings({
test_dataset_week <- lgb.Dataset(data = as.matrix(test_data_week[, -c("Count","Date")]),
                            label = test_data_week$Count,
                            categorical_feature = c("season", "mnth"
                            ))
})

# Specify LightGBM parameters
params <- list(objective = "regression",
               metric = "rmse",
               boosting_type = "gbdt")

params$silent <- TRUE
# Train the LightGBM model
suppressWarnings({
  lgb_model_week <- lgb.train(params = params,
                              data = train_dataset_week,
                              nrounds = 100,
                              valids = list(test = test_dataset_week))
})

suppressWarnings({
lgb_pred_week <- predict(lgb_model_week, as.matrix(test_data_week[, -c("Count","Date")]))
})

lgb_rmse_week <- sqrt(mean((lgb_pred_week - test_data_week$Count)^2))

print(paste0("LightGBM RMSE Week forecast:", lgb_rmse_week ))

df12_week <- data.frame(
  Date = test_data_week$Date,
  Actual = test_data_week$Count,
  Predited = lgb_pred_week
)

suppressWarnings({
df12_week = rbind(data.frame(
  Date = train_data_week$Date,
  Actual = train_data_week$Count,
  Predited = predict(lgb_model_week, as.matrix(train_data_week[, -c("Count","Date")]))
),
df12_week
)
})

# Plotting using ggplot2
week_wise <- ggplot(df12_week, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual")) +
  geom_line(aes(y = Predited, color = "Predited")) +
  labs(
    title = "LightGBM Model by Week",
    subtitle = "Bikeshare usage Acutal vs Predicted",
    x = "Time in Weeks",
    y = "Average Bike Usage",
    caption = paste("RMSE:", round(lgb_rmse_week, 3))
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Predited" = "red")) +
  theme_minimal()

grid.arrange(day_wise, week_wise, ncol = 1)
# day_wise
# week_wise

```

However, despite the overall success in capturing trends, there's a notable limitation in predicting the increase in usage observed in 2017. The RMSE (Root Mean Squared Error) of weekly forecast is lower than daily forecast as it is able to remove the noise in the data and capture it well. Nevertheless, the model still struggles to accurately predict the surge in usage during 2017.

## Model Performance

Overall, ARIMA and LightGBM do the best on our dataset, with RMSE of `1503.639` and `1552.007` respectively. We can see that the RMSE is still fairly high for both of the models, but when predicting bike share usage we don't need perfect results. The main goal is to stay ahead of the customer usage, which we believe either of our models are capable of performing. 

ARIMA has a much better ability at forecasting for trend and seasonality. The major issue is that it doesn't take into account any other variables. You can think of it as all the variables have been "baked" into the usage and, therefore, it is only trying to forecast the usage. If we went through extremely hot or cold temperatures, ARIMA's model doesn't take that into account so will need time to start adjusting its output to reflect that change.

LightGBM does a better job at utilizing features such as weather to better predict the usage of the bikes. The issue is that it is not able to accurately predict future usage because it doesn't take into account trend or seasonality.

# Conclusion

One finding was that forecasting effectively requires more data than two years of usage. Our initial time series models trained on 2011-2012 data and performed poorly. They were unable to learn the trend and seasonality with so few data points.

We also validated that linear regression was not an optimal approach to this data, which makes sense given our use of time series data. We could have used a linear regression model if we captured trend and seasonality as a feature for the model. ARIMA and LightGBM were much better suited to predicting future increase as well as matching seasonality patterns. ARIMA and LightGBM both have their pitfalls, but we discussed the possibility of feeding in the ARIMA's output into our LightGBM model as one of its features, but didn't have the time to test this. This would have allowed the LightGBM model to have trend and seasonality prediction as features. We do believe that the combination of these two models would be useful for this and other bike sharing programs, but were unable to verify the results.

One key finding is that because daily usage fluctuates significantly, using mean of weekly usage smoothed our data and led to much better-performing models. In this case we felt this was beneficial, because as noted above, any bikeshare system would likely be adding new vehicles to the fleet or subtracting vehicles for maintenance on a weekly or monthly basis rather than on a daily basis. This also helped reduce outliers' affect on the data set, and random fluctuations in the data.

# Literature Review Summary

We reviewed a few papers modeling bikeshare usage in different cities across the globe (see Works Cited). These papers generally shared the same findings, which largely align with our Capital Bikeshare data:

* Usage increases as temperature increases, then starts to decrease as temperatures go into the 90s (Fahrenheit)
* Precipitation of any amount discourages cycling
* High winds can have a negative effect on cycling
* Usage is often higher in spring and summer, and lowest in winter

# Works Cited

Bean, R., Pojani, D., & Corcoran, J. (2021). How does weather affect bikeshare use? A comparative analysis of forty cities across climate zones. _Journal of Transport Geography_, 95. https://doi.org/10.1016/j.jtrangeo.2021.103155.

Eren, E., & Uz, V. E. (2020). A review on bike-sharing: The factors affecting bike-sharing demand. _Sustainable Cities and Society_, 54. https://doi.org/10.1016/j.scs.2019.101882

Ashgar, H. I., Elhenawy, M., & Rakha, H. A. (2019). Modeling bike counts in a bike-sharing system considering the effect of weather conditions. _Case Studies on Transport Policy_, 7(2), 261-268. https://doi.org/10.1016/j.cstp.2019.02.011
